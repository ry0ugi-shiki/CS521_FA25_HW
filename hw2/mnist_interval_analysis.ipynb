{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe70a96",
   "metadata": {},
   "source": [
    "## Interval Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bbda12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize()\n",
       "  (1): Net(\n",
       "    (0): Normalize()\n",
       "    (1): Linear(in_features=784, out_features=200, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=200, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorboardX\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from bound_propagation import BoundModelFactory, HyperRectangle\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "## Dataloaders\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"mnist_data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    \"mnist_data/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "## Simple NN. You can change this if you want. If you change it, mention the architectural details in your report.\n",
    "class Normalize(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - 0.1307) / 0.3081\n",
    "\n",
    "\n",
    "class Net(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__(\n",
    "            Normalize(), nn.Linear(28 * 28, 200), nn.ReLU(), nn.Linear(200, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 28 * 28))\n",
    "        x = super().forward(x)\n",
    "        x = F.softmax(x, dim=-1)  # added softmax for probabilities\n",
    "        return x\n",
    "\n",
    "\n",
    "# Add the data normalization as a first \"layer\" to the network\n",
    "# this allows us to search for adverserial examples to the real image, rather than\n",
    "# to the normalized image\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a6282f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.3f}')\n",
    "\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print(f'Accuracy on images: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72dd8bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.718\n",
      "Epoch 2/10, Loss: 1.570\n",
      "Epoch 3/10, Loss: 1.552\n",
      "Epoch 4/10, Loss: 1.541\n",
      "Epoch 5/10, Loss: 1.534\n",
      "Epoch 6/10, Loss: 1.528\n",
      "Epoch 7/10, Loss: 1.523\n",
      "Epoch 8/10, Loss: 1.519\n",
      "Epoch 9/10, Loss: 1.516\n",
      "Epoch 10/10, Loss: 1.513\n",
      "Accuracy on images: 95.11\n"
     ]
    }
   ],
   "source": [
    "train_model(model, 10)\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c23f92",
   "metadata": {},
   "source": [
    "### Write the interval analysis for the simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d97f7f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.01, Robust Accuracy: 70.27%\n",
      "Epsilon: 0.020000000000000004, Robust Accuracy: 15.34%\n",
      "Epsilon: 0.030000000000000006, Robust Accuracy: 1.17%\n",
      "Epsilon: 0.04000000000000001, Robust Accuracy: 0.02%\n",
      "Epsilon: 0.05000000000000001, Robust Accuracy: 0.00%\n",
      "Epsilon: 0.06000000000000001, Robust Accuracy: 0.00%\n",
      "Epsilon: 0.07, Robust Accuracy: 0.00%\n",
      "Epsilon: 0.08, Robust Accuracy: 0.00%\n",
      "Epsilon: 0.09000000000000001, Robust Accuracy: 0.00%\n",
      "Epsilon: 0.1, Robust Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "## TODO: Write the interval analysis for the simple model\n",
    "## you can use https://github.com/Zinoex/bound_propagation\n",
    "#  !pip install bound-propagation\n",
    "from bound_propagation import BoundModelFactory, HyperRectangle\n",
    "\n",
    "\n",
    "net = BoundModelFactory().build(model)\n",
    "\n",
    "\n",
    "def interval_analysis(net, test_loader, epsilons):\n",
    "    with torch.no_grad():\n",
    "        for e in epsilons:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for imgs, labels in test_loader:\n",
    "                box = HyperRectangle.from_eps(imgs.view(imgs.size(0), -1), e)\n",
    "                out = net.crown_ibp(box, alpha=True).concretize()\n",
    "                lo, hi = out.lower, out.upper\n",
    "\n",
    "                labs = labels.cpu().numpy()\n",
    "                bad_mask = torch.ones_like(hi, dtype=torch.bool, device=hi.device)\n",
    "                for idx, lab in enumerate(labs):\n",
    "                    bad_mask[idx, lab] = False\n",
    "                lo_true = lo[range(len(labels)), labs]\n",
    "                hi_bad = hi.masked_select(bad_mask).view(len(labels), -1)\n",
    "                correct += (lo_true > hi_bad.max(dim=1).values).sum().item()\n",
    "                total += len(labels)\n",
    "            print(f\"Epsilon: {e}, Robust Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "epsilons = np.linspace(0.01, 0.1, 10)\n",
    "interval_analysis(net, test_loader, epsilons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
